{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGTB6Y/XJ9IUT+egFY+pwQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kSyYxr_HVY5o",
        "outputId": "b135a8d1-6e68-4439-bfc5-574a858ff324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "ERROR: unknown command \"isinstall\" - maybe you meant \"install\"\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install textblob\n",
        "%pip isinstall seaborn\n",
        "%pip install statsmodels\n",
        "%pip install matplotlib\n",
        "%pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#revision\n",
        "\n",
        "import nltk\n",
        "import os, os.path\n",
        "import nltk.data\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZh2jn6UVq9v",
        "outputId": "247eed37-00a8-4db7-c1f9-755c7ce761a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = r'AirForceVeteranUsesVR.txt'\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f: # Open the file\n",
        "        text = f.read() # Read the file\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except UnicodeDecodeError:\n",
        "    print(f\"Error: Unicode decoding error. Try a different encoding (e.g., 'latin-1') for {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "GmpNgAsKVvvu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(text)\n",
        "nltk_text = nltk.Text(tokens)\n",
        "nltk_text.concordance(\"VR\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Xoez0CVyKP",
        "outputId": "6b6362d3-637b-4931-8d38-fc58f03abfc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 13 of 13 matches:\n",
            "get some of my health back by getting VR so this is like being here is kind of\n",
            "irst thing I 'd want to ask is how is VR helped you with the PTSD that you exp\n",
            " just automatically go there and also VR has helped me because um I work out i\n",
            "as helped me because um I work out in VR because of the nature of my other phy\n",
            "ef so like I can actually work out in VR and then I can go to the grocery stor\n",
            "that sensation when I meet friends in VR chat and we hug each other if if my b\n",
            " to help me I think I started playing VR chat just before I started taking the\n",
            "t get into it at first I did n't have VR and then um as my condition started g\n",
            " an Oculus Rift and I started playing VR chat and I started playing VR games t\n",
            "playing VR chat and I started playing VR games that let me escape from it and \n",
            "d my PTSD and I mean I had been using VR up to that point obviously but I duri\n",
            "hen I 'm in that state and yeah using VR like I said was what got me out of it\n",
            "o long after I started working out in VR that I was able to um start walking w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_text.similar(\"PTSD\")\n",
        "\n",
        "fdist = nltk.FreqDist(tokens)\n",
        "print(fdist.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZAMidB5V1l7",
        "outputId": "09d52809-26cc-4c6e-93ef-38deef78abdb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medication pain things name and like the ass thing people because when\n",
            "brain body relief stuff state time moment military\n",
            "[('I', 401), ('it', 168), ('and', 167), ('the', 156), ('to', 154), ('was', 149), ('that', 147), ('of', 135), ('a', 107), ('my', 96)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#.Remove Stop Words and Punctuation (Important!)\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "cleaned_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stopwords]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDlxBemcWEjK",
        "outputId": "31690de8-d681-4f9d-b57c-6b337fabebc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. Calculate Frequency Distribution\n",
        "fdist = nltk.FreqDist(cleaned_tokens)\n",
        "# Print Most Common\n",
        "print(fdist.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Jwbci0WY0L",
        "outputId": "21d62cb9-070d-4b24-e999-7d696ab69724"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('like', 96), ('started', 46), ('um', 36), ('get', 33), ('people', 33), ('would', 30), ('know', 28), ('pain', 26), ('really', 25), ('ptsd', 24)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
        "fdist = nltk.FreqDist(lemmatized_tokens)\n",
        "print(fdist.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pufc0kJWdF7",
        "outputId": "f20a955f-2b6f-4c04-e609-476393ea7e91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('like', 96), ('started', 46), ('um', 36), ('get', 35), ('people', 33), ('would', 30), ('know', 28), ('medication', 27), ('pain', 26), ('thing', 26)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer  # Import Porter Stemmer\n",
        "stemmer = PorterStemmer()  # Initialize Porter Stemmer\n",
        "stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]  # Stem tokens\n",
        "fdist = nltk.FreqDist(stemmed_tokens)  # Calculate Frequency Distribution   # Print Most Common\n",
        "print(fdist.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqElKOwKWuF2",
        "outputId": "75004201-7cbc-4a2f-b62a-851cef73d43c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('like', 96), ('start', 54), ('get', 45), ('um', 36), ('peopl', 33), ('would', 30), ('go', 29), ('know', 29), ('medic', 28), ('pain', 26)]\n"
          ]
        }
      ]
    }
  ]
}